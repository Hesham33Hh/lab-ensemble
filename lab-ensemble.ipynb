{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with the same Spaceship Titanic data, like the previous Lab. The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab, you should try different ensemble methods in order to see if can obtain a better model than before. In order to do a fair comparison, you should perform the same feature scaling, engineering applied in previous Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PassengerId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "HomePlanet",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CryoSleep",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Cabin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Destination",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VIP",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "RoomService",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FoodCourt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ShoppingMall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Spa",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VRDeck",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Transported",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "f12c4ba7-f2d0-4d14-8f4b-c6b46d7ab9f6",
       "rows": [
        [
         "0",
         "0001_01",
         "Europa",
         "False",
         "B/0/P",
         "TRAPPIST-1e",
         "39.0",
         "False",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "Maham Ofracculy",
         "False"
        ],
        [
         "1",
         "0002_01",
         "Earth",
         "False",
         "F/0/S",
         "TRAPPIST-1e",
         "24.0",
         "False",
         "109.0",
         "9.0",
         "25.0",
         "549.0",
         "44.0",
         "Juanna Vines",
         "True"
        ],
        [
         "2",
         "0003_01",
         "Europa",
         "False",
         "A/0/S",
         "TRAPPIST-1e",
         "58.0",
         "True",
         "43.0",
         "3576.0",
         "0.0",
         "6715.0",
         "49.0",
         "Altark Susent",
         "False"
        ],
        [
         "3",
         "0003_02",
         "Europa",
         "False",
         "A/0/S",
         "TRAPPIST-1e",
         "33.0",
         "False",
         "0.0",
         "1283.0",
         "371.0",
         "3329.0",
         "193.0",
         "Solam Susent",
         "False"
        ],
        [
         "4",
         "0004_01",
         "Earth",
         "False",
         "F/1/S",
         "TRAPPIST-1e",
         "16.0",
         "False",
         "303.0",
         "70.0",
         "151.0",
         "565.0",
         "2.0",
         "Willy Santantines",
         "True"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature scaling y selección completados\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Extraer columnas de Cabin\n",
    "spaceship[[\"Deck\", \"Cabin_num\", \"Side\"]] = spaceship[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "\n",
    "# Eliminar columnas irrelevantes\n",
    "spaceship.drop(columns=[\"PassengerId\", \"Name\", \"Cabin\"], inplace=True)\n",
    "\n",
    "# Definir target\n",
    "y = spaceship[\"Transported\"].astype(int)\n",
    "X = spaceship.drop(columns=[\"Transported\"])\n",
    "\n",
    "# Definir columnas\n",
    "num_cols = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Cabin_num\"]\n",
    "cat_cols = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"Deck\", \"Side\"]\n",
    "\n",
    "# Pipelines para numéricas y categóricas\n",
    "num_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, num_cols),\n",
    "        (\"cat\", cat_transformer, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"✅ Feature scaling y selección completados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Tamaño del train: (6954, 13)\n",
      "📊 Tamaño del test: (1739, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,    # 20% para test\n",
    "    random_state=42,  # reproducibilidad\n",
    "    stratify=y        # mantiene proporción de clases\n",
    ")\n",
    "\n",
    "print(f\"📊 Tamaño del train: {X_train.shape}\")\n",
    "print(f\"📊 Tamaño del test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection** - now you will try to apply different ensemble methods in order to get a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy Bagging: 0.8039\n",
      "✅ Accuracy Pasting: 0.7510\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Clasificador base\n",
    "base_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 🔹 Bagging (bootstrap=True)\n",
    "bagging_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", BaggingClassifier(\n",
    "        estimator=base_clf,\n",
    "        n_estimators=100,\n",
    "        max_samples=1.0,\n",
    "        bootstrap=True,  # Con reemplazo\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging_clf.predict(X_test)\n",
    "acc_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "print(f\"✅ Accuracy Bagging: {acc_bagging:.4f}\")\n",
    "\n",
    "# 🔹 Pasting (bootstrap=False)\n",
    "pasting_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", BaggingClassifier(\n",
    "        estimator=base_clf,\n",
    "        n_estimators=100,\n",
    "        max_samples=1.0,\n",
    "        bootstrap=False,  # Sin reemplazo\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pasting_clf.fit(X_train, y_train)\n",
    "y_pred_pasting = pasting_clf.predict(X_test)\n",
    "acc_pasting = accuracy_score(y_test, y_pred_pasting)\n",
    "print(f\"✅ Accuracy Pasting: {acc_pasting:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌲 Accuracy Random Forest: 0.8068\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 🔹 Random Forest\n",
    "rf_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(\n",
    "        n_estimators=200,       # más árboles para mayor estabilidad\n",
    "        max_depth=None,         # sin límite de profundidad\n",
    "        random_state=42,\n",
    "        n_jobs=-1               # usar todos los núcleos\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Entrenar\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar\n",
    "rf_acc = rf_clf.score(X_test, y_test)\n",
    "print(f\"🌲 Accuracy Random Forest: {rf_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Accuracy Gradient Boosting: 0.8074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# 🔹 Gradient Boosting\n",
    "gb_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Entrenar\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar\n",
    "gb_acc = gb_clf.score(X_test, y_test)\n",
    "print(f\"⚡ Accuracy Gradient Boosting: {gb_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Accuracy AdaBoost: 0.8022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# 🔹 AdaBoost\n",
    "ada_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", AdaBoostClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Entrenar\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "acc_ada = accuracy_score(y_test, y_pred_ada)\n",
    "print(f\"⚡ Accuracy AdaBoost: {acc_ada:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is the best and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model in your experiment is Gradient Boosting, because:\n",
    "\n",
    "It achieved the highest accuracy: 0.8074.\n",
    "\n",
    "Gradient Boosting trains models sequentially, with each new tree correcting the mistakes of the previous ones, which helps reduce bias.\n",
    "\n",
    "This makes it very effective at capturing complex patterns in the data compared to bagging-based methods like Random Forest or AdaBoost.\n",
    "\n",
    "While Random Forest was very close in accuracy (0.8068), Gradient Boosting slightly outperformed it and often has better potential with further tuning.\n",
    "\n",
    "Final choice: Gradient Boosting is the best performer in this case due to its balance of accuracy and ability to model non-linear relationships in the dataset.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
